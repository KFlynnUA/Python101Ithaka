{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding sentences that match a word or phrase\n",
    "\n",
    "8/19/21\n",
    "\n",
    "Research question:\n",
    "\n",
    ">We would like to identify any sentences in dataset that match the word/pharse X and ouput those to a file.\n",
    "\n",
    "This research question will require a Constellate dataset that contains the full text of the document. There are over You can create these in the Constellate application by selecting \"Full text only\" from the \"Download Availability\" filter. Here are example datasets to work with: \n",
    "\n",
    "* `f477f1df-6cd5-c12e-844e-a04128e9b6e5`: All documents from JSTOR published in Proceedings of the American Philosophical Society from 1900 - 1930\n",
    "\n",
    "* `88a2bfb7-7196-0ca4-d545-d066ae8cc52c`: All documents from JSTOR published in The American Economic Review from 1910 - 1930 and limited to full text availability\n",
    "\n",
    "First, import Python libraries to help us with our analysis. We will use the [Natural Language Toolkit](https://www.nltk.org/) to parse the raw text into sentences and the Pandas library for plotting and outputting the matched sentences to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constellate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset and specify the matching text\n",
    "\n",
    "Download a dataset created in the Constellate application into the notebook environment.\n",
    "\n",
    "Add the dataset id that you are interested in retreiving as the `dataset_id` variable. This can be found on your [dashboard](https://constellate.org/dataset/dashboard) in the Constellate web application.\n",
    "\n",
    "Next, define the `matching_phrase` variable that you want to find in the text of the documents. This can be any string and a case insensitive match will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"88a2bfb7-7196-0ca4-d545-d066ae8cc52c\"\n",
    "matching_phrase = \"inflation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = constellate.get_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the dataset into sentences\n",
    "\n",
    "Loop through all documents in the dataset, read the `fullText` field, which is an array of page text, and parse sentences using nltk's sentence parser. Check each sentence to see if it contains the matching phrase (case insensitive) and save matches to a Python list. We will record the document identifier, publication year, the page sequence number where the sentence was found, the sentence sequence number within that page, and the text of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matching_phrase = matching_phrase.lower().strip()\n",
    "matched_sentences = []\n",
    "matched = 0\n",
    "n = 0\n",
    "\n",
    "for document in constellate.dataset_reader(dataset_file):\n",
    "    publication_year = document[\"publicationYear\"]\n",
    "    for page_sequence, raw_page_text in enumerate(document.get(\"fullText\")):\n",
    "        # Replace all line breaks with spaces.\n",
    "        page = \" \".join(raw_page_text.split())\n",
    "        for sentence_sequence, sentence in enumerate(sent_tokenize(page)):\n",
    "            if matching_phrase in sentence.lower():\n",
    "                matched_sentences.append((document[\"id\"], publication_year, page_sequence, sentence_sequence, sentence))\n",
    "                matched += 1\n",
    "    n += 1\n",
    "    if (n % 100) == 0:\n",
    "       print(f\"{n} documents scanned\", document[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prview the matched sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_sentences[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sentence dataframe\n",
    "\n",
    "Create a pandas DataFrame from the matched sentences. This makes it convenient to output as a CSV or analyze further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df = pd.DataFrame(matched_sentences, columns=[\"id\", \"publication_year\", \"page_seq\", \"sentence_seq\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot matching sentences over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df.groupby(\"publication_year\").size()\\\n",
    "  .plot(kind=\"bar\", title=\"Matching sentences over time\", xlabel=\"publication year\", ylabel=\"matching sentences\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output a csv file with the matching senctences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_file = f\"{dataset_id}-sentences.csv\"\n",
    "\n",
    "sentence_df.to_csv(sent_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
